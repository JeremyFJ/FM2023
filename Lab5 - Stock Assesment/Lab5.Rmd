---
title: "Lab 5 - Stock Assessment part 1: Log-likelihood and Surplus Production"
author: "(Your name here)"
date: "2/16/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
lab_path = dirname(rstudioapi::getSourceEditorContext()$path)
knitr::opts_knit$set(root.dir = lab_path)
getwd()
set.seed(9999)
```

```{r}
# install.packages('remotes')
# remotes::install_github("haddonm/datalowSA")
# library(datalowSA)
library(tidyverse)
```

# Stock Assessment

## Log-Likelihood
*Log-Likelihood*: The natural logarithm of the likelihood. 
*Likelihood*: A function that gives us multiple probability distributions of observing the given samples

### Linear regression around standard error

Simulating distributions, linear regression, and parameter estimation/optimization
```{r}
# y = mx + b
b = 3 # this is the intercept
m = 0.5 # this is the slope
sigma = 5
x = runif(200, min = 2, max = 56) # let's generate a set of 200 x values going from 2 to 56
mu = m*x + b # now we generate a series of response values without error
err2 = rnorm(200,mean=0,sd = sigma) # let's assume the error is normally distributed with mean 0 and sd  = 5
y = mu+err2 # add error to mean
```

```{r}
model1 = lm(y~x) # least squares estimation
plot(y~x)
abline(model1)
summary(model1)
```

```{r}
par(mfrow=c(2,2))
plot(model1)
```

Let's write a function to return the negative logarithmic distribution of our intercept and slope parameter estimates. We can use `dnorm()` to calculate the distribution around predicted response values
```{r}
fun_negLL = function(m, b) {
	Y.pred = m * x + b 
	-sum(dnorm(y, mean = Y.pred, sd = 5, log = T))
	}
```

We can optimize our regression parameters with a `nested for loop` using the function above and a generated list of parameter values
```{r}
# building a search grid
b_list = seq(0.01,10,0.01) # list of b parameter
m_list = seq(0.01,10,0.01) # list of m parameter
params = matrix(NA,nrow=1000,ncol=1000,dimnames = list(b_list,m_list)) # parameter matrix
for (i in 1:length(b_list)){ # for every 'b' test 'm'
 	for (j in 1:length(m_list)){ 
		params[i,j] = fun_negLL(b = b_list[i], m = m_list[j])
		}
	}
# the optimized parameters 
bopt = rownames(params)[which(params==min(params),arr.ind=T)[1]] # b - intercept
mopt = colnames(params)[which(params==min(params),arr.ind=T)[2]] # m - slope
cat(paste0("b: ",bopt,"\nm: ",mopt))
```

```{r}
model1$coefficients
```

```{r}
plot(seq(0.01,10,0.01),
     params[,mopt], 
     type = "l", 
     ylab = "-LogLikelihood", 
     xlab = "Intercept")
```

Use the optimization function
`?optim`
```{r}
pars = c(b=b, m=m, sigma=sigma)
fun_negLL = function(par, x, y) {
# Parameters
	b = par[1]
	m = par[2]
	err.sigma = par[3]
# Model
	Y.pred = m*x+b 
# -LL
	-sum(dnorm(y, mean = Y.pred, sd = sigma, log = T))
	}

paropt = optim(par = pars, fn = fun_negLL, x=x, y=y, # parameters, function to optimize, x,y
               lower=c(1,0.1,3), upper = c(4,1,10), # lower and upper bounds of parameter
               method="L-BFGS-B", hessian = T) # Byrd etal, 1995 opt method allows bounds for params
paropt$par
```
Are these estimates close to the estimates from above?

```{r}
b_pred = paropt$par[1]
m_pred = paropt$par[2]
Y.pred = m_pred*x+b_pred
residual <- y-Y.pred
plot(x, residual, ylab="Residuals", xlab="independent variable")
abline(h=0, col="red")
```

## Surplus Production

*Surplus production models* are especially useful when evaluating biomass and exploitation levels of fish stocks that are data-deficient (particularly if age and size is not reported)

The FRDC (Fisheries Research and Development Corporation) reports metrics of various fish stocks around Australia from 1986-2016 and can be accessed with the **datalowSA** package.
```{r}
data(dataspm)
fish = dataspm$fish
```

Use the `getlag()` function to look at the correlation between CPUE and catches. Negative correlation is indicative of the CPUE being informative of catch throughout the years where data is being recorded 
```{r}
getlag(fish, maxlag = 10, plotout = TRUE, indexI = 1) # check lag
```

Changes in population biomass can tell us the relationship between fishing mortality rates and population growth. Surplus production models (`SPMs`) are important baselines for determining exploitation of stocks. 

Here, we will assume that the maximum sustainable biomass is equal to the carrying capacity 
$$
B_{max} \approx K
$$
\\
$$
\text{Schaefer}\\
B_{t+1} = B_t + rB_t(1-B_t/K)-C_t\\
\text{Fox}\\
B_{t+1} = B_t + rB_t(1-logB_t/logK)-Ct
$$

`Bt` = exploitable population biomass at time (t)
`r` = intrinsic population growth rate
`K` = carrying capacity
`Ct` = catch at time (t)

Define our set of parameters.
Predict biomass (similar to how we modeled exponential growth) using the Schaefer SPM model
```{r}
pars = c(r=0.2,K=6000,Binit=2800) # initial parameters

B = c()
B[1] = pars["Binit"]
C = fish$catch
```

```{r}
pars[[3]]/pars[[2]] # annual depletion based on above parameters, Binit/K
```

Use the Schaefer model equation to predict population biomass (and incorporate catches) and use a for-loop with 30 time steps

This function should use the above model to predict population biomass.
```{r}
r = pars["r"]
K = pars["K"]
time = seq(1, 30, 1)
for (i in time){
  B[i+1] = B[i] + r*B[i]*(1-B[i]/K) - C[i]
}
B
```

### Calculating Relative Abundance
$$
\text{Index of relative abundance}\\
I_t = qB_t
$$
`q` = catchability coefficient

Estimating `q` from the data
```{r}
cpue = fish$cpue
# estimating q from the data
qs = cpue/B
q = mean(qs)
pred.cpue.e = B*q 
```

Relating catches to the biomass by using the average biomass at the start and end of year (t)
$$
CPUE = (B_{t+1} + B_t) / 2q
$$

```{r}
pred.cpue.e2 = (B[2:31]+B[1:30])/2*q
```

Use `simpspm` with parameters, observations, and Schaefer model 
```{r}
pred.cpue = simpspm(pars, fish, schaefer = TRUE)
```

Plot the different CPUE predictions vs. time 
```{r}
ggplot() +
  geom_point(aes(x=time, y=cpue[1:30]), pch=15, size=2, color="black") +
  geom_line(aes(x=time, y=pred.cpue[1:30]), color="red") +
  geom_line(aes(x=time, y=pred.cpue.e[1:30]), color="green") + 
  geom_line(aes(x=time, y=pred.cpue.e2), color="blue") +
  xlab("Time") + 
  ylab("CPUE") +
  theme(panel.border = element_rect(fill=NA),
        panel.grid = element_line(size=0.07, color="black"))
```


Let's use our parameters to evaluate depletion, catch, surplus production, and predicted CPUE with one function `displayModel` from the `datalowSA` package.
```{r}
ans = displayModel(pars,fish,schaefer = TRUE, addrmse = TRUE)
str(ans)
```

`ExploitB Depletion`: displays the trajectory of the exploitable biomass depletion rate. The red line is the LRP and the green line is the TRP. In Schaefer model results, two options are similar 
`Catch`: displays the catch series with MSY as red line
`Scaled CPUE`: displays the model fit to the CPUE data. Red line is the model predictions and the black dots are the CPUE data points
`Surplus Production - Biomass`: displays surplus production vs. biomass. Vertical red lines represent $B_{lim}$, $B_{targ}$, and $B_{MSY}$ and the horizontal dash line is MSY
`LN Residuals`: displays the residuals (scaled observe CPUE / scaled predicted CPUE) with a value of RMSE (root mean square error)
`Surplus Production - Depletion`: displays the surplus production vs. depletion function. The vertical lines represent the LRP (red, limit reference point) and TRP (green, target reference point) and MSY (blue)

Now let's plot the harvest rate vs. Biomass 
```{r}
spmphaseplot(ans, fnt=7)
```
This plot identifies the start and end years (green and red dots). It also plots out the catch time-series and harvest rate time-series.

Let's use the loglikelihood function of the lognormal distribution to optimize our model
$$
\hat{\sigma}^2 = \sum_t\frac{(\ln I_t-\ln\hat{I_t})^2}{n}
$$
The `negLL()` function calculates the negative log-likelihood using this equation 
$$
LL = -\frac{n}{2}(\ln(2\pi)+2\ln(\hat{\sigma})+1)
$$
The `optim()` function is a general-purpose parameter optimization function that takes a list of parameters, data, and function as arguments
```{r}
out <- optim(par=pars, fn=negLL, callfun=simpspm, 
                indat=fish)
out$par
```

Let's use our optimized parameters to fit a new model
```{r}
B = c()
B[1] = out$par["Binit"]
C = fish$catch

r = out$par["r"]
K = out$par["K"]
time = seq(1, 30, 1)
for (i in time){
  B[i+1] = B[i] + r*B[i]*(1-B[i]/K) - C[i]
}
B
```

```{r}
cpue = fish$cpue
# estimating q from the data
qs = cpue/B
q = mean(qs)
pred.cpue.e = B*q 
```

Plot your data and compare the models - use a legend
```{r}
ggplot() +
  geom_point(aes(x=time, y=cpue[1:30]), pch=15, size=2, color="black") +
  geom_line(aes(x=time, y=pred.cpue.e[1:30]), color="green") + 
  xlab("Time") + 
  ylab("CPUE") +
  theme(panel.border = element_rect(fill=NA),
        panel.grid = element_line(size=0.07, color="black"))
```

```{r}
par(mfrow=c(2,2))
lm2 = lm(log(pred.cpue.e)~log(cpue))
plot(lm2)
```

```{r}
ans1 = displayModel(out$par,fish,schaefer = TRUE, addrmse = TRUE) 
spmphaseplot(ans1, fnt=7)
```
